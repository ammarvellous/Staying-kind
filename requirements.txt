# Core
transformers>=4.42.0
accelerate>=0.31.0
datasets>=2.20.0

# Quantization for 4-bit loading
bitsandbytes>=0.43.0

# PyTorch stack (keep versions in the same minor family)
torch>=2.3.0,<2.6.0
torchvision>=0.18.0,<0.20.0
torchaudio>=2.3.0,<2.6.0

# Optional: flash-attn (install separately to match your CUDA/torch)
# flash-attn    # install with: pip install flash-attn --no-build-isolation
